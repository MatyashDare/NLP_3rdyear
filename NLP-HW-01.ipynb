{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоматическая обработка языка\n",
    "## НИУ ВШЭ, 2020-2021 учебный год\n",
    "\n",
    "### Домашнее задание №1\n",
    "\n",
    "Задание выполнил(а): Дарья Матяш\n",
    "\n",
    "Ссылка на условия и требования: https://github.com/named-entity/hse-nlp/blob/master/Hometask%201.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках этого заадания мы будем создавать программу, которая получая на вход отзыв, будет предсказывать, является ли отзыв положительным или отрицательным. \n",
    "\n",
    "Делать мы будем это таким образом: \n",
    "\n",
    "\n",
    "1)мы возьмём некоторое число заранее размеченных как положительные или отрицательные отзывов\n",
    "\n",
    "2)выделим те слова, которые встречаются только в положительных или только в отрицательных отзывах\n",
    "\n",
    "3)и будем считать, каких слов в поступившем нам на проверку отзыве больше.\n",
    "\n",
    "\n",
    "**Мы будем работать по заранее определённому пайплайну:**\n",
    "\n",
    "\n",
    "1)Сначала нам надо **скачать дату** -- соберите как минимум 60 (30 положительных и 30 отрицательных) отзывов на похожие продукты (не надо мешать отзывы на отели с отзывами на ноутбуки) для составления \" тонального словаря\" (чем больше отзывов, тем лучше) и 10 отзывов для проверки качества. **3 балла** в случае сбора путём **парсинга**, 1 - если найдете уже готовые данные или просто закопипастите без парсинга\n",
    "\n",
    "\n",
    "2)Токенизируйте слова, приведите их к нижнему регистру и к начальной форме (**1 балл** за **токенизацию**, **1** - за **начальную форму**)\n",
    "\n",
    "\n",
    "3)Составьте **2 множества** - в одном будут слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных. Попробуйте поиграть с **частотностями и исключить шум** (к примеру, выбросить слова, встречающиеся 1-2 раза) (**3 балла**) (если у вас получились пустые множества, уберите фильтр по частотности или увеличьте выборку)\n",
    "\n",
    "\n",
    "4)Создайте функцию, которая будет определять, **положительный ли отзыв или отрицательный** в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи **accuracy** (**1** - за коректно работающую функцию, **1** - за подсчёт accuracy)\n",
    "\n",
    "\n",
    "5)Предложите как минимум 2 способа **улучшить** эту программу с помощью добавления к ней любых мулек - просто словами, писать улучшающий код не надо (**1 балл**)\n",
    "Логичность и чистота кода (**1 балл**)\n",
    "Да, тут **12 баллов** - два можно потерять.\n",
    "В случае, если после долгих мучений в п. 3 множества по объективным причинам не получается (покажите, что пытались) - отправляйте жабу - зачьтём полный балл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Импортируем все нужные модули\n",
    "(на самом деле, удобнее намного импортировать \"по ходу пьесы\", поэтому некоторые импорты сделаны далее)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "\n",
    "headers = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Сбор данных\n",
    "\n",
    "Я очень хотела воспользоваться сайтом irecommend.ru, но, к сожалению, там беда с сервером этого сайта и я воспользовлась всем известным tripadvisor, не заморачивалась с API, тк было мало времени(из-за проблем с irecommend) и вообще очень просто выкачиваются отзывы, но, безусловно, использование API облегчило бы жизнь. Еще можно было бы пользоваться beautifulsoup,но здесь быстро и суперпросто написать регулярки и все))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные буду брать с сайта tripadvisor - отзывы о ТЦ \"Центральный Детский магазин\", \"Европейский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rev_list = []\n",
    "neg_rev_list = []\n",
    "final_rates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_split_func(x):\n",
    "    re_split = re.split(r':?(\\.|!|\\?)\\s?\\s?', x)\n",
    "    if re_split[-1][-7:] == 'hellip;':\n",
    "        ans = re.sub('[|\\.|\\?|!|,|\\(|\\)|-]','',re.sub(':?(\\</.*\\>|&quot;)',' ',' '.join(re_split[:-1])))\n",
    "    else:\n",
    "        ans = re.sub('[|\\.|\\?|!|,|\\(|\\)|-]','',re.sub(':?(\\</.*\\>|&quot;)',' ',' '.join(re_split)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    if i == 0:\n",
    "        page = \"https://www.tripadvisor.ru/Attraction_Review-g298484-d7394028-Reviews-Aviapark_Mall-Moscow_Central_Russia.html\"\n",
    "    elif i < 60:\n",
    "        page = \"https://www.tripadvisor.ru/Attraction_Review-g298484-d7394028-Reviews-or{0}-Aviapark_Mall-Moscow_Central_Russia.html#REVIEWS\".format( i* 5)\n",
    "    elif i == 60:\n",
    "        page = \"https://www.tripadvisor.ru/Attraction_Review-g298484-d543281-Reviews-Central_Children_s_Store-Moscow_Central_Russia.html#REVIEWS\"\n",
    "    else:\n",
    "        page = \"https://www.tripadvisor.ru/Attraction_Review-g298484-d543281-Reviews-or{0}-Central_Children_s_Store-Moscow_Central_Russia.html#REVIEWS\".format(i * 5)\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    html = requests.get(page, headers=headers).text\n",
    "    review_text = re.findall(r'<q class=\"IRsGHoPm\"><span>(.*?)</span></q></div>',html, flags=re.DOTALL)\n",
    "    review_rate = re.findall(r'ata-test-target=\"review-rating\"><span class=\"ui_bubble_rating bubble_(.)0\"',html)\n",
    "    for r in range(len(review_text)):\n",
    "        if review_rate[r] == '5':\n",
    "            if len(pos_rev_list) <=42:\n",
    "                pos_rev_list.append(review_text[r])\n",
    "                final_rates.append(5)\n",
    "        elif review_rate[r] == '1' and review_text[r] not in neg_rev_list:\n",
    "            if len(neg_rev_list) <=42:\n",
    "                neg_rev_list.append(review_text[r])\n",
    "                final_rates.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получилось по 42 отзыва - отрицательных оказалось несколько меньше, поэтому уберем небольшую разницу (у автора кода небольшая проблема с математикой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Конечно брать детей сюда нельзя, или много денег с собой брать нельзя :) ничего подобного нигде не видел', 'Большой и красивый ТЦ в центре города. Есть много разных магазинов, кинотеатр, фудкорт, музеи и смотровая площадка.', 'Лет двадцать я не был здесь. И увиденное повергло меня в уныние. Как говорится, был &quot;Детский мир&quot;, да сплыл. От &quot;Детского мира&quot; ничего не осталось. Всё изменено: планировка, дизайн, наполнение. Самое главное, исчез его дух. Все превратилось в ярмарку тщеславия и понтов. Бренды,</span><span class=\"_1M-1YYJt\"> которые никто не покупает, потому что немыслимо дорого для простого человека.  Как жаль, как даль. Не знаю, что и сказать...</span><span>&hellip;', 'Помню этот магазин ещё с начала 70-х годов. Недавно заходи с внуком. Реконструкция координально всё изменила. Наверное к лучшему. Много товаров, что-то выбрать стало сложнее. Ну и цены конечно не для пенсионеров. Они для новых русских...детей) Можно перекусить. Машинку свою</span><span class=\"_1M-1YYJt\"> внук, кстати, получил....</span><span>&hellip;', 'Огромный и красивый изнутри торговый центр Детский Мир,  есть магазины как для детей так и для взрослых. Кинотеатр,  фудкорт, смотровая площадка.']\n",
      "['5', '5', '3', '5', '5']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'<q class=\"IRsGHoPm\"><span>(.*?)</span></q></div>',html, flags=re.DOTALL))\n",
    "print(re.findall(r'ata-test-target=\"review-rating\"><span class=\"ui_bubble_rating bubble_(.)0\"',html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos_rev_list), len(neg_rev_list), len(final_rates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кладем в список final_texts положительные и отрицательные отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_texts = pos_rev_list  + neg_rev_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Токенизиция слов, привод их к нижнему регистру и лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "lemmatizer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я хочу создать базу данных и сохранить туда все, потому что считаю, что нужно все сохранять. Могу приложить бд к репозиторию домашки, чтобы, елси что, можно было удостовериться, что я не вру:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'reviews': final_texts,\n",
    "                'rates': final_rates})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Есть абсолютно все, можно приходить на целый в...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>В настоящее время ТЦ Авиапарк проталкивает про...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Случайно попали в торговый центр и были приятн...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews  rates\n",
       "29  Есть абсолютно все, можно приходить на целый в...      5\n",
       "46  В настоящее время ТЦ Авиапарк проталкивает про...      5\n",
       "24  Случайно попали в торговый центр и были приятн...      5"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем функцию, с помощью которой \"почистим\" немного отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_split_func(x):\n",
    "    re_split = re.split(r':?(\\.|!|\\?)\\s?\\s?', x)\n",
    "    if re_split[-1][-7:] == 'hellip;':\n",
    "        if len(re_split) > 1:\n",
    "            ans = re.sub('[|\\.|\\?|!|,|\\(|\\)]','',re.sub(':?(\\</.*\\>|&quot;)',' ',' '.join(re_split[:-1])))\n",
    "        else:\n",
    "            ans = re.sub('[|\\.|\\?|!|,|\\(|\\)]','',re.sub(':?(\\</.*\\>|&quot;)',' ',' '.join(re_split)[:-21]))\n",
    "    else:\n",
    "        ans = re.sub('[|\\.|\\?|!|,|\\(|\\)]','',re.sub(':?(\\</.*\\>|&quot;)',' ',' '.join(re_split)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_spl'] = df['reviews'].apply(re_split_func)\n",
    "df['lemmas'] = df['reviews_spl'].apply(lambda x: re.sub(r'\\n','',''.join(lemmatizer.lemmatize(' '.join(tokenizer.tokenize(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rates</th>\n",
       "      <th>reviews_spl</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Живем недалеко раньше часто ездили, но больше ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Живем недалеко раньше часто ездили но больше н...</td>\n",
       "      <td>жить недалеко рано часто ездить но больше не б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Осень большой торговый центр. Мне больше всего...</td>\n",
       "      <td>5</td>\n",
       "      <td>Осень большой торговый центр  Мне больше всего...</td>\n",
       "      <td>осень большой торговый центр я много все понра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Очень нравится ТЦ &amp;quot;Авиапарк&amp;quot;, своим ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Очень нравится ТЦ  Авиапарк  своим расположени...</td>\n",
       "      <td>очень нравиться тц авиапарк свой расположение ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews  rates  \\\n",
       "47  Живем недалеко раньше часто ездили, но больше ...      1   \n",
       "15  Осень большой торговый центр. Мне больше всего...      5   \n",
       "42  Очень нравится ТЦ &quot;Авиапарк&quot;, своим ...      5   \n",
       "\n",
       "                                          reviews_spl  \\\n",
       "47  Живем недалеко раньше часто ездили но больше н...   \n",
       "15  Осень большой торговый центр  Мне больше всего...   \n",
       "42  Очень нравится ТЦ  Авиапарк  своим расположени...   \n",
       "\n",
       "                                               lemmas  \n",
       "47  жить недалеко рано часто ездить но больше не б...  \n",
       "15  осень большой торговый центр я много все понра...  \n",
       "42  очень нравиться тц авиапарк свой расположение ...  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай сохраняю датафрейм, приложу на всякий случай в репозиторий:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NLP-HW1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Создание множеств слов, встречающихся только в позитивных и только в негативных отзывах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим множества слов, состоящих только в положительных или только в отрицательныч отзывах на 38 отзывов  и протестируем на 10 отзывах из каждой категории соотвественно.\n",
    "\n",
    "Ниже я не могу сказать, что нужно обязательно делать какие-то сложные функции, код на 5 строчек, если было бы больше классов, имело бы смсыл засовывать все в функции, но, кажется, так \"ручками\" сделать два сета, два словаря и тд - не такая уж и беда:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rev_lem_list = df[(df['rates']==5)]['lemmas'].to_list()[:-10]\n",
    "neg_rev_lem_list = df[(df['rates']==1)]['lemmas'].to_list()[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_string_pos = ''\n",
    "for el in pos_rev_lem_list:\n",
    "    to_string_pos += ' ' + el\n",
    "to_string_neg = ''\n",
    "for el in neg_rev_lem_list:\n",
    "    to_string_neg += ' ' + el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pos_rev_c = Counter(to_string_pos.split())\n",
    "neg_rev_c = Counter(to_string_neg.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 441\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_rev_dict), len(neg_rev_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Выведем топ 10 самых частотных и 10 самых редких токенов для позитивных отзывов и негативных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['в', 'и', 'центр', 'торговый', 'быть', 'для', 'на', 'хороший', 'много', 'с']\n",
      "['дешевый', 'везде', 'взять', 'деньги', 'развлекаться', 'наверное', 'зал', 'чистый', 'кухня', 'вкусный']\n"
     ]
    }
   ],
   "source": [
    "print([tup[0] for tup in pos_rev_c.most_common(10)])\n",
    "print([tup[0] for tup in pos_rev_c.most_common()[:-11:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', '-', 'на', 'не', 'быть', 'тц', 'с', 'по', 'парковка']\n",
      "['вводить', 'бы', 'убирать', 'лишать', 'немного', 'возможность', 'неделя', 'закупаться', 'муж', 'непонятно']\n"
     ]
    }
   ],
   "source": [
    "print([tup[0] for tup in neg_rev_c.most_common(10)])\n",
    "print([tup[0] for tup in neg_rev_c.most_common()[:-11:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При лемматизации и токенизации я не использовала стоп-слова, потому что они в основном и являются самыми частотными в обоих случаях, видим знак '-' - я не убирала его, тк не хотела проблем со словами типа \"70-х\" и т.д., оставила но, в любом случае, сейчас уберу \n",
    "Какие вообще слова стоит оставлять? По-хорошему надо посмотреть на распределение слов, посмотреть на среднюю встречаемость слова и убирать слова, встрчающиеся реже 1-2 раз или чаще какого-то среднего значения встречаемости + какое-то n\n",
    "Я посмотрела \"руками\" на примерное распределение по выборке и сделала разные пороги частоты слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rev_set = set([tup[0] for tup in pos_rev_c.most_common() if 25 > tup[1] > 1 and tup[0].isalpha()])\n",
    "neg_rev_set = set([tup[0] for tup in neg_rev_c.most_common() if 50 > tup[1] > 1 and tup[0].isalpha()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем сеты со словами (леммами) в только позитивных или только негативных отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_pos = pos_rev_set - pos_rev_set.intersection(neg_rev_set)\n",
    "only_neg = neg_rev_set - pos_rev_set.intersection(neg_rev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Создание функции, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём\n",
    "\n",
    "\n",
    "Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy (1 - за коректно работающую функцию, 1 - за подсчёт accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_sent(x):\n",
    "    pos_sent = 0\n",
    "    neg_sent = 0\n",
    "    for word in x.split():\n",
    "        if word in only_pos:\n",
    "            pos_sent +=1\n",
    "        elif word in only_neg:\n",
    "            neg_sent +=1\n",
    "        else:\n",
    "            pass\n",
    "    if pos_sent > neg_sent:\n",
    "        return 5\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df[(df['rates']==5)]['lemmas'].to_list()[-10:] + df[(df['rates']==1)]['lemmas'].to_list()[-10:]\n",
    "y_test = df[(df['rates']==5)]['rates'].to_list()[-10:] + df[(df['rates']==1)]['rates'].to_list()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем предсказание положительных тестов и посчитаем (сделала для этого мини-функцию) accuracy на тесте, а потом применим функцию, которая покажет, как в целом предсказания раюотают на всей выборке (да, странно брать обучающую выборку, но я считаю, что тк у нас максмально \"руками\" способ предсказывать тональность текста, то так сделать немножко можно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(X, y):\n",
    "    ans = 0\n",
    "    for i in range(len(X)):\n",
    "        if which_sent(X[i]) != y[i]:\n",
    "            ans += 1\n",
    "    return ans/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовой выборке:  0.45\n"
     ]
    }
   ],
   "source": [
    "print('accuracy на тестовой выборке: ', count_accuracy(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим accuracy на всей (вообще, когда я делала ПОБОЛЬШЕ отзывов, было реально ЛУЧШЕ НАМНОГО)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predictions'] = df['lemmas'].apply(which_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rates</th>\n",
       "      <th>reviews_spl</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Я конечно понимаю, что 26 марта 2020 года «сто...</td>\n",
       "      <td>5</td>\n",
       "      <td>Я конечно понимаю что 26 марта 2020 года «стоя...</td>\n",
       "      <td>я конечно понимать что 26 март 2020 год « стоя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Цена откровенно завышена. 200-400 руб за 2-3 м...</td>\n",
       "      <td>1</td>\n",
       "      <td>Цена откровенно завышена  200-400 руб за 2-3 м...</td>\n",
       "      <td>цена откровенно завышать 200 - 400 руб за 2 - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Самый интересный и хороший места в Москве.там ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Самый интересный и хороший места в Москве  там...</td>\n",
       "      <td>самый интересный и хороший место в москва там ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews  rates  \\\n",
       "45  Я конечно понимаю, что 26 марта 2020 года «сто...      5   \n",
       "60  Цена откровенно завышена. 200-400 руб за 2-3 м...      1   \n",
       "7   Самый интересный и хороший места в Москве.там ...      5   \n",
       "\n",
       "                                          reviews_spl  \\\n",
       "45  Я конечно понимаю что 26 марта 2020 года «стоя...   \n",
       "60  Цена откровенно завышена  200-400 руб за 2-3 м...   \n",
       "7   Самый интересный и хороший места в Москве  там...   \n",
       "\n",
       "                                               lemmas  \n",
       "45  я конечно понимать что 26 март 2020 год « стоя...  \n",
       "60  цена откровенно завышать 200 - 400 руб за 2 - ...  \n",
       "7   самый интересный и хороший место в москва там ...  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8194444444444444\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(df['predictions'], df['rates']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Предложения улучшения качества работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Можно точно **увеличить выборку** раз так в ТЫСЯЧУ, ну хотя бы в сто, чтобы была возможность \"увидеть\" какие-то еще закономерности и т.д.\n",
    "\n",
    "2) Можно попробовать использовать **TF-IDF** или другие способы **векторного представления слов**, чтобы брались не \"вслепую\" просто по частотности слова, а чтобы учитывался езе такой параметр, как кол-во вхождений односительно всего документа (это в случае с TF-IDF я говорю) Или вообще заиспользовать что-то из разряда **word2vec**, чтобы еще в кодировке каждого слова \"лежала\" информация о его, так сказать, контекстных \"предпочтениях\"\n",
    "\n",
    "3) Можно попробовать поработать не только с униграммами, но и **би- и три-граммами** (больше не вижу смысла)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
